"""
    Large-scale Point Cloud Semantic Segmentatishapeon with Superpoint Graphs
    #具有超点图的大规模点云语义分割方法
    http://arxiv.org/abs/1711.09869
    2017 Loic Landrieu, Martin Simonovsky
"""

from __future__ import division
from __future__ import print_function
from builtins import range

import torch
import torch.nn as nn
import torch.nn.init as init
import ecc
from modules import RNNGraphConvModule, ECC_CRFModule, GRUCellEx, LSTMCellEx


    # Creates feature-generating network, a multi-layer perceptron.
    # #创建特征生成网络，一个多层感知器，就是一个全连接的深度学习网络
    # Parameters 参数含义:
    # widths: list of widths of layers (including input and output widths)
    # #图层宽度列表（包括输入和输出宽度）
    # orthoinit: whether to use orthogonal weight initialization
    ##orthoinit:是否使用正交权重初始化
    # llbias: whether to use bias in the last layer
    ##libias：是否在最后一层使用偏差
    # bnidx: index of batch normalization (-1 if not used)
    ##bnidx:批量标准化的索引（如果不用则为-1）

def create_fnet(widths, orthoinit, llbias, bnidx=-1):  #返回一个建立的模型
#nn.Linear函数，参数为输入和输出值的维度
#init.orthogonal（Tensor，gain=1）函数，正交矩阵初始化参数，参数Tensor为n维torch.Tensor且n>=2
#init.calculate_gain()函数，返回给定非线性函数的增益值
#nn.BatchNorm1d函数，对小批量输入进行批标准化操作，该层计算每次输入的均值与方差，并进行移动平均
    fnet_modules = []
    for k in range(len(widths)-2):
        fnet_modules.append(nn.Linear(widths[k], widths[k+1]))
        if orthoinit:
            init.orthogonal(fnet_modules[-1].weight, gain=init.calculate_gain('relu'))#返回‘relu’的增益值，为根2
        if bnidx==k:
            fnet_modules.append(nn.BatchNorm1d(widths[k+1]))
        fnet_modules.append(nn.ReLU(True))#nn.ReLU激活函数，TRUE表示覆盖运算
    fnet_modules.append(nn.Linear(widths[-2], widths[-1], bias=llbias))
    if orthoinit:
        init.orthogonal(fnet_modules[-1].weight)
    if bnidx==len(widths)-1:
        fnet_modules.append(nn.BatchNorm1d(fnet_modules[-1].weight.size(0)))
    return nn.Sequential(*fnet_modules)#nn.Sequential函数可以快速构建神经网络



class GraphNetwork(nn.Module): #nn.Module类，定义自己的神经网络，必须要继承nn.Module类
    """ It is constructed in a flexible way based on `config` string, which contains sequence of comma-delimited layer definiton tokens layer_arg1_arg2_... See README.md for examples.
    """
    #基于‘config’字符串以灵活的方式构造，其中包含逗号分隔的序列
    def __init__(self, config, nfeat, fnet_widths, fnet_orthoinit=True, fnet_llbias=True, fnet_bnidx=-1, edge_mem_limit=1e20):
        super(GraphNetwork, self).__init__()  # nn.Module的子类函数必须在构造函数中执行父类的构造函数
        self.gconvs = []
            for d, conf in enumerate(config.split(',')):  # split用于将大文件分割成小文件，config为配置
                conf = conf.strip().split('_')  # 这一句相当于按照‘_’分割文件

            if conf[0]=='f':    #Fully connected layer全连接层;  args: output_feats
                self.add_module(str(d), nn.Linear(nfeat, int(conf[1])))
                nfeat = int(conf[1])
            elif conf[0]=='b':  #Batch norm 批量规范;             args: not_affine无仿射
                self.add_module(str(d), nn.BatchNorm1d(nfeat, eps=1e-5, affine=len(conf)==1))
            elif conf[0]=='r':  #ReLU;nn.rule()函数，对输入运用修正线性单元函数，TRUE表示进行覆盖运算
                self.add_module(str(d), nn.ReLU(True))
            elif conf[0]=='d':  #Dropout;正则化                args: dropout_prob
                self.add_module(str(d), nn.Dropout(p=float(conf[1]), inplace=False))
            elif conf[0]=='crf': #ECC-CRF;               args: repeats
                nrepeats = int(conf[1])

                fnet = create_fnet(fnet_widths + [nfeat*nfeat], fnet_orthoinit, fnet_llbias, fnet_bnidx)
                gconv = ecc.GraphConvModule(nfeat, nfeat, fnet, edge_mem_limit=edge_mem_limit)
                crf = ECC_CRFModule(gconv, nrepeats)
                self.add_module(str(d), crf)
                self.gconvs.append(gconv)

            #设定参数值
            elif conf[0]=='gru' or conf[0]=='lstm': #RNN-ECC     args: repeats, mv=False, layernorm=True, ingate=True, cat_all=True
                nrepeats = int(conf[1])
                vv = bool(int(conf[2])) if len(conf)>2 else True # ECC是否具有矩阵值多元素或元素多元素
                layernorm = bool(int(conf[3])) if len(conf)>3 else True
                ingate = bool(int(conf[4])) if len(conf)>4 else True
                cat_all = bool(int(conf[5])) if len(conf)>5 else True

                fnet = create_fnet(fnet_widths + [nfeat**2 if not vv else nfeat], fnet_orthoinit, fnet_llbias, fnet_bnidx)
                if conf[0]=='gru':
                    cell = GRUCellEx(nfeat, nfeat, bias=True, layernorm=layernorm, ingate=ingate)
                else:
                    cell = LSTMCellEx(nfeat, nfeat, bias=True, layernorm=layernorm, ingate=ingate)
                gconv = RNNGraphConvModule(cell, fnet, nrepeats=nrepeats, cat_all=cat_all, edge_mem_limit=edge_mem_limit)
                self.add_module(str(d), gconv)
                self.gconvs.append(gconv)
                if cat_all: nfeat *= nrepeats + 1

            elif len(conf[0])>0:
                raise NotImplementedError('Unknown module: ' + conf[0])


    def set_info(self, gc_infos, cuda):
        """ Provides convolution modules with graph structure information for the current batch.
        """
        #为卷积模块提供当前批次的图形结构信息
        gc_infos = gc_infos if isinstance(gc_infos,(list,tuple)) else [gc_infos]
        for i,gc in enumerate(self.gconvs):
            if cuda: gc_infos[i].cuda()
            gc.set_info(gc_infos[i])

    def forward(self, input):
        for module in self._modules.values():
            input = module(input)
        return input

